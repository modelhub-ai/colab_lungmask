{
  "id": "0002",
  "meta": {
    "name": "colab_lungmask",
    "application_area": "Google CoLab",
    "task": "Segmentation",
    "task_extended": "Lung segmentation - Google CoLab Notebook - Segmentation",
    "data_type": "Image/CT scan",
    "framework": "colab",
    "colab_link": "https://github.com/modelhub-ai/colab_lungmask/blob/main/lungmask_mwe.ipynb",
    "github_link": "https://github.com/JoHof/lungmask"
  },
  "publication": {
    "title": "Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem",
    "source": "https://doi.org/10.1186/s41747-020-00173-2",
    "year": 2020,
    "authors": "Hofmanninger, J., Prayer, F., Pan, J., Röhrich, S., Prosch, H., & Langs, G.",
    "abstract": "Background: Automated segmentation of anatomical structures is a crucial step in image analysis. For lung segmentation in computed tomography, a variety of approaches exists, involving sophisticated pipelines trained and validated on different datasets. However, the clinical applicability of these approaches across diseases remains limited. Methods: We compared four generic deep learning approaches trained on various datasets and two readily available lung segmentation algorithms. We performed evaluation on routine imaging data with more than six different disease patterns and three published data sets. Results: Using different deep learning approaches, mean Dice similarity coefficients (DSCs) on test datasets varied not over 0.02. When trained on a diverse routine dataset (n = 36), a standard approach (U-net) yields a higher DSC (0.97 ± 0.05) compared to training on public datasets such as the Lung Tissue Research Consortium (0.94 ± 0.13, p = 0.024) or Anatomy 3 (0.92 ± 0.15, p = 0.001). Trained on routine data (n = 231) covering multiple diseases, U-net compared to reference methods yields a DSC of 0.98 ± 0.03 versus 0.94 ± 0.12 (p = 0.024). Conclusions: The accuracy and reliability of lung segmentation algorithms on demanding cases primarily relies on the diversity of the training data, highlighting the importance of data diversity compared to model choice. Efforts in developing new datasets and providing trained models to the public are critical. By releasing the trained model under General Public License 3.0, we aim to foster research on lung diseases by providing a readily available tool for segmentation of pathological lungs.",
    "url": "https://doi.org/10.1186/s41747-020-00173-2",
    "google_scholar": "https://scholar.google.com/scholar?cites=70004818277158591&as_sdt=40000005&sciodt=0,22&hl=en",
    "bibtex": "@article{hofmanninger2020automatic, title={Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem}, author={Hofmanninger, Johannes and Prayer, Forian and Pan, Jeanny and Rohrich, Sebastian and Prosch, Helmut and Langs, Georg}, journal={European Radiology Experimental}, volume={4}, number={1}, pages={1--13}, year={2020}, publisher={SpringerOpen}}"
  },
  "model": {
    "description": "This notebook provides a minimal working example of LungMask, a tool for the segmentation of the the lungs and the lung lobes from non-contrast CT images robust to the presence of severe pathologies. In particular, in this notebook we make use the fusion between the results of the R231 and LTRCLobes models. We test LungMask by implementing an end-to-end (cloud-based) pipeline on publicly available chest CT scans hosted on the Imaging Data Commons (IDC), starting from raw DICOM CT data and ending with a DICOM SEG object storing the segmentation masks generated by the AI model. The testing dataset we use is external and independent from the data used in the development phase of the model (training and validation) and is composed of a wide variety of image types (from image acquisition settings, to the presence of a contrast agent, to the presence, location and size of a tumor mass). The way all the operations are executed - from pulling data to data postprocessing and the standardisation of the results - have the goal of promoting transparency and reproducibility.",
    "provenance": "",
    "architecture": "",
    "learning_type": "",
    "format": "",
    "io": {
      "input": {
        "format": [],
        "single":{
          "format": [],
          "dim_limits": [
          {
            "min": 0,
            "max": 0
          },
          {
            "min": 0
          },
          {
            "min": 0
          }
        ],
         "description":""
        },
        "description": ""
      },
      "output": [
        {
          "name": "",
          "type": "",
          "description": ""
        }
      ]
    }
  },
  "modelhub": {}
}
